---
---

@string{aps = {American Physical Society,}}

@misc{McMahon2022,
title = {Hierarchical representations of naturalistic social interactions in the lateral visual pathway},
author = {Emalie McMahon and Michael Bonner and Leyla Isik},
year={2022},
url={https://2022.ccneuro.org/view_paper.php?PaperNum=1063},
pdf = {McMahon2022_CCN.pdf},
abbr = {CCN},
pdf = {McMahon2022_CCNpaper.pdf},/Users/jim9/Desktop/Github /imelizabeth.github.io/_bibliography/papers.bib
poster = {McMahon2022_CCNposter.pdf},
doi={10.32470/CCN.2022.1063-0},
abstract = {In our daily lives, we quickly and effortlessly perceive features of others’ interactions. Extracting these social details is crucial for deciding how to act in the social world, but little is understood about how this is solved in the mind and brain. Recent work has identified a visually-selective region for the presence of a social interaction in posterior superior temporal sulcus (pSTS), but whether and how diverse features of a social interaction (ranging from visual to high-level) are presented in the pSTS or elsewhere in the brain is unknown. To answer this question, we showed participants 250 3-second video clips of naturalistic two-person interactions while undergoing fMRI. We used an encoding model approach to model where visual and social features of the videos are represented in the brain. We replicate known preference for scene and object features in visual cortex. We also find preference for facing bodies in EBA and joint action in pSTS, extending prior findings with controlled stimuli to natural settings. Finally, we identify regions along the extent of the STS that show a preference for third-party communication. Together, these results suggest a hierarchy of visual to social feature processing along the lateral surface of the brain.}
}

@misc{Lam2021,
title={Understanding Mental Representations Of Objects Through Verbs Applied To Them},
author={Ka Chun Lam and Francisco Pereira and Maryam Vaziri-Pashkam and Kristin Woodard and Emalie McMahon},
year={2021},
url={https://openreview.net/forum?id=tw60PTRSda2},
pdf = {Lam2021_CogSci.pdf},
abbr = {CogSci},
abstract = {In order to interact with objects in our environment, we rely on an understanding of the actions that can be performed on them, and the extent to which they rely or have an effect on the properties of the object. This knowledge is called the object “affordance”. We propose an approach for creating an embedding of objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. Furthermore, we show that the dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. Finally, we show that the dimensions can be used to predict a state-of-the-art mental representation of objects, derived purely from human judgements of object similarity.}
}

@article{McMahon2021,
    author = {McMahon, Emalie and Kim, Daniel and Mehr, Samuel A. and Nakayama, Ken and Spelke, Elizabeth S. and Vaziri-Pashkam, Maryam},
    title = {The ability to predict actions of others from distributed cues is still developing in 6- to 8-year-old children},
    journal = {Journal of Vision},
    volume = {21},
    number = {5},
    pages = {14-14},
    year = {2021},
    month = {05},
    abstract = { Adults use distributed cues in the bodies of others to predict and counter their actions. To investigate the development of this ability, we had adults and 6- to 8-year-old children play a competitive game with a confederate who reached toward one of two targets. Child and adult participants, who sat across from the confederate, attempted to beat the confederate to the target by touching it before the confederate did. Adults used cues distributed through the head, shoulders, torso, and arms to predict the reaching actions. Children, in contrast, used cues in the arms and torso, but we did not find any evidence that they could use cues in the head or shoulders to predict the actions. These results provide evidence for a change in the ability to respond rapidly to predictive cues to others’ actions from childhood to adulthood. Despite humans’ sensitivity to action goals even in infancy, the ability to read cues from the body for action prediction in rapid interactive settings is still developing in children as old as 6 to 8 years of age. },
    issn = {1534-7362},
    doi = {10.1167/jov.21.5.14},
    url = {https://doi.org/10.1167/jov.21.5.14},
    pdf = {McMahon2021_JoV.pdf},
    abbr = {JoV},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/jov/938529/i1534-7362-21-5-14\_1621070987.66637.pdf},
pdf = {McMahon2021_JoV.pdf}
}

@article{McMahon2019,
    author = {McMahon, Emalie G. and Zheng, Charles Y. and Pereira, Francisco and Gonzalez, Ray and Ungerleider, Leslie G. and Vaziri-Pashkam, Maryam},
    title = {Subtle predictive movements reveal actions regardless of social context},
    journal = {Journal of Vision},
    volume = {19},
    number = {7},
    pages = {16-16},
    year = {2019},
    month = {07},
    abstract = { Humans have a remarkable ability to predict the actions of others. To address what information enables this prediction and how the information is modulated by social context, we used videos collected during an interactive reaching game. Two participants (an “initiator” and a “responder”) sat on either side of a plexiglass screen on which two targets were affixed. The initiator was directed to tap one of the two targets, and the responder had to either beat the initiator to the target (competition) or arrive at the same time (cooperation). In a psychophysics experiment, new observers predicted the direction of the initiators' reach from brief clips, which were clipped relative to when the initiator began reaching. A machine learning classifier performed the same task. Both humans and the classifier were able to determine the direction of movement before the finger lift-off in both social conditions. Further, using an information mapping technique, the relevant information was found to be distributed throughout the body of the initiator in both social conditions. Our results indicate that we reveal our intentions during cooperation, in which communicating the future course of actions is beneficial, and also during competition despite the social motivation to reveal less information.},
    issn = {1534-7362},
    doi = {10.1167/19.7.16},
    url = {https://doi.org/10.1167/19.7.16},
    pdf = {McMahon2019_JoV.pdf},
    abbr = {JoV},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/jov/938093/i1534-7362-19-7-16.pdf}
}

@article {Corbetta2018,
      author = {Daniela Corbetta and Rebecca F. Wiener and Sabrina L. Thurman and Emalie McMahon},
      title = {The Embodied Origins of Infant Reaching: Implications for the Emergence of Eye-Hand Coordination},
      journal = {Kinesiology Review},
      year = {2018},
      publisher = {Human Kinetics},
      address = {Champaign IL, USA},
      volume = {7},
      number = {1},
      doi = {10.1123/kr.2017-0052},
      pages = {10 - 17},
      url = {https://journals.humankinetics.com/view/journals/krj/7/1/article-p10.xml},
      pdf = {Corbetta2018_KinesiologyReview.pdf},
      abbr = {Kin Rev},
      abstract = {This article reviews the literature on infant reaching, from past to present, to recount how our understanding of the emergence and development of this early goal-directed behavior has changed over the decades. We show that the still widely-accepted view, which considers the emergence and development of infant reaching as occurring primarily under the control of vision, is no longer sustainable. Increasing evidence suggests that the developmental origins of infant reaching is embodied. We discuss the implications of this alternative view for the development of eye-hand coordination and we propose a new scenario stressing the importance of the infant body-centered sensorimotor experiences in the months prior to the emergence of reaching as a possible critical step for the formation of eye-hand coordination. }

}
